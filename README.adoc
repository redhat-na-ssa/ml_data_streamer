== source-eip

=== Test 

. Clone this project and change directories into it:
+
-----
$ https://github.com/redhat-na-ssa/ml_data_streamer \
    && cd ml_data_streamer
-----

==== Run Container as Root

. Create CSV directory:
+
-----

$ export csv_dir=/tmp/com_rht_na_gtm_source
$ mkdir -p $csv_dir
-----

. Start `source-eip` app as linux-container:
+
-----
$ export kafka_node_ip=172.30.209.80
$ export kafka_node_port=32909

$ podman run  -it --rm \
    --publish 8080:8080 \
    --name source-eip \
    -e "JAVA_OPTS=-Dkafka.bootstrap.servers=$kafka_node_ip:$kafka_node_port -Dcom.rht.na.gtm.source.location=$csv_dir" \
    -v $csv_dir:$csv_dir:Z \
    -u root \
    quay.io/redhat_naps_da/ml_data_streamer-source-eip:0.0.1
-----

. Trigger source-eip service:
+
-----
$ cp source-eip/src/test/resources/samples/MUFG-1.csv \
     source-eip/src/test/resources/samples/MUFG-2.csv \
     source-eip/src/test/resources/samples/MUFG-3.csv \
     $csv_dir
-----

==== Run Container as Rootless

. Start `source-eip` app as linux-container:
+
-----
$ export kafka_node_ip=172.30.209.80
$ export kafka_node_port=32009

$ export csv_dir=/tmp/com_rht_na_gtm_source
$ mkdir -p $csv_dir \
    && sudo chmod -R 775 $csv_dir \
    && sudo semanage fcontext -a \
        -t container_file_t "$csv_dir(/.*)?" \
    && sudo restorecon -R $csv_dir
$ podman unshare chown 185:$(id -g) -R $csv_dir
$ podman unshare ls -al $csv_dir

$ podman run  -it --rm \
        --publish 8080:8080 \
        --name source-eip \
        -e "JAVA_OPTS=-Dkafka.bootstrap.servers=$kafka_node_ip:$kafka_node_port -Dcom.rht.na.gtm.source.location=$csv_dir" \
        -v $csv_dir:$csv_dir:Z \
        --group-add keep-groups \
        quay.io/redhat_naps_da/ml_data_streamer-source-eip:0.0.1
-----

. Trigger source-eip service:
+
-----
$ podman unshare cp \
    source-eip/src/test/resources/samples/MUFG-1.csv \
    source-eip/src/test/resources/samples/MUFG-2.csv \
    source-eip/src/test/resources/samples/MUFG-3.csv \
    $csv_dir
-----

=== Deployment

. Create topic:
+
-----
$ export topic_name=csv-financials
$ echo "kind: KafkaTopic
apiVersion: kafka.strimzi.io/v1beta2
metadata:
  name: $topic_name
  labels:
    strimzi.io/cluster: $topic_name
spec:
  partitions: 10
  replicas: 3
  config:
    retention.ms: 604800000
    segment.bytes: 1073741824" \
| oc apply -n user1-ml-data-streamer -f -

-----

. Create a node port service for kafka broker:
+
-----
$ export kafka_node_port=32909
$ echo "apiVersion: v1
kind: Service
metadata:
  name: kafka-bootstrap-nodeport
  labels:
    name: kafka-bootstrap-nodeport
spec:
  type: NodePort
  ports:
    - port: 9092
      nodePort: $kafka_node_port
      name: kafka
  selector:
    strimzi.io/cluster: kafka-cluster
    strimzi.io/kind: Kafka
    strimzi.io/name: kafka-cluster-kafka" \
| oc apply -n user1-ml-data-streamer -f -
-----


=== Development
. Start quarkus runnable jar:
+
-----
$ java  \
    -Dkafka.bootstrap.servers=rht:32009 \
    -Dcom.rht.na.gtm.source.location=/tmp/com_rht_na_gtm_source/ \
    -Dcom.rht.na.gtm.topic.name=csv-financials \
    -jar source-eip/target/quarkus-app/quarkus-run.jar
-----

. Build and push source-eip container to quay:
+
-----
$ ./mvnw clean package \
            -DskipTests \
            -Dquarkus.application.name=ml_data_streamer-source-eip \
            -Dquarkus.container-image.build=true \
            -Dquarkus.container-image.push=true
-----



== sink-eip

=== Deployment

-----
$ oc apply \
    -k config_mgmt/gitops-dev/bootstrap/deploy/ml-data-streamer-sink-eip/
    -n user1-ml-data-streamer
-----

=== Development

. Build and push sink-eip container to quay:
+
-----
$ ./mvnw clean package \
            -DskipTests \
            -Dquarkus.application.name=ml-data-streamer-sink-eip \
            -Dquarkus.container-image.build=true \
            -Dquarkus.container-image.push=true
-----
